{"ast":null,"code":"var _jsxFileName = \"/Users/craigpickard/Dev/web/hbo-client/src/components/FaceTracker.js\";\nimport React, { useEffect, useState } from \"react\";\nimport * as facemesh from \"@tensorflow-models/facemesh\";\nimport _isNil from \"lodash/isNil\";\nimport { TRIANGULATION } from \"./triangulation\"; // const useAnimationFrame = (callback) => {\n//   // Use useRef for mutable variables that we want to persist\n//   // without triggering a re-render on their change\n//   const requestRef = React.useRef();\n//   const previousTimeRef = React.useRef();\n//   const animate = (time) => {\n//     if (previousTimeRef.current != undefined) {\n//       const deltaTime = time - previousTimeRef.current;\n//       callback(deltaTime);\n//     }\n//     previousTimeRef.current = time;\n//     requestRef.current = requestAnimationFrame(animate);\n//   };\n//   React.useEffect(() => {\n//     requestRef.current = requestAnimationFrame(animate);\n//     return () => cancelAnimationFrame(requestRef.current);\n//   }, []); // Make sure the effect runs only once\n// };\n\nconst triangulateMesh = true;\n\nfunction drawPath(ctx, points, closePath) {\n  const region = new Path2D();\n  region.moveTo(points[0][0], points[0][1]);\n\n  for (let i = 1; i < points.length; i++) {\n    const point = points[i];\n    region.lineTo(point[0], point[1]);\n  }\n\n  if (closePath) {\n    region.closePath();\n  }\n\n  ctx.stroke(region);\n}\n\nconst FaceTracker = ({\n  videoRef,\n  userId,\n  stream\n}) => {\n  const [count, setCount] = React.useState(0);\n  const [trackingEnabled, setTrackingEnabled] = useState(false);\n  const [videoLoaded, setVideoLoaded] = useState(false);\n  const [uuid, setUuid] = useState(null);\n  let faces = [];\n  let model = null;\n  let ctx, videoWidth, videoHeight, video, canvas;\n  useEffect(() => {\n    _init();\n  }, [stream]);\n\n  async function _init() {\n    model = await facemesh.load(); // Pass in a video stream to the model to obtain\n    // an array of detected faces from the MediaPipe graph.\n    // video = document.querySelector(\"video\");\n\n    video = document.getElementById(`video-${userId}`);\n    video.srcObject = stream;\n    video.addEventListener(\"loadeddata\", async event => {\n      console.log(\"Yay! The readyState just increased to  \" + \"HAVE_CURRENT_DATA or greater for the first time.\");\n      videoWidth = video.videoWidth;\n      videoHeight = video.videoHeight;\n      video.width = videoWidth;\n      video.height = videoHeight;\n      canvas = document.getElementById(`output-${userId}`);\n      canvas.width = videoWidth;\n      canvas.height = videoHeight;\n      const canvasContainer = document.querySelector(\".canvas-wrapper\");\n      canvasContainer.style = `width: ${videoWidth}px; height: ${videoHeight}px`;\n      ctx = canvas.getContext(\"2d\");\n      ctx.translate(canvas.width, 0);\n      ctx.scale(-1, 1);\n      ctx.fillStyle = \"#32EEDB\";\n      ctx.strokeStyle = \"#32EEDB\";\n      ctx.lineWidth = 0.5;\n      setVideoLoaded(true);\n      renderPrediction();\n    });\n  }\n\n  async function renderPrediction() {\n    ctx.drawImage(video, 0, 0, videoWidth, videoHeight, Math.floor(parseInt(userId) * canvas.width), Math.floor(parseInt(userId) * canvas.height), canvas.width, canvas.height);\n\n    if (trackingEnabled) {\n      const predictions = await model.estimateFaces(video);\n\n      if (predictions.length > 0) {\n        predictions.forEach(prediction => {\n          const keypoints = prediction.scaledMesh;\n\n          if (triangulateMesh) {\n            for (let i = 0; i < TRIANGULATION.length / 3; i++) {\n              const points = [TRIANGULATION[i * 3], TRIANGULATION[i * 3 + 1], TRIANGULATION[i * 3 + 2]].map(index => keypoints[index]);\n              drawPath(ctx, points, true);\n            }\n          } else {\n            for (let i = 0; i < keypoints.length; i++) {\n              const x = keypoints[i][0];\n              const y = keypoints[i][1];\n              ctx.beginPath();\n              ctx.arc(x, y, 1\n              /* radius */\n              , 0, 2 * Math.PI);\n              ctx.fill();\n            }\n          }\n        });\n      }\n    } // ctx.clearRect(0, 0, canvas.width, canvas.height);\n\n\n    requestAnimationFrame(renderPrediction);\n  } //   useAnimationFrame(async (deltaTime) => {\n  //     // Pass on a function to the setter of the state\n  //     // to make sure we always have the latest state\n  //     console.log(\"animate\");\n  //     if (model !== null) faces = await model.estimateFaces(video);\n  //     // faces.forEach((face) => console.log(face.scaledMesh));\n  //     console.log(faces.length);\n  //   });\n\n\n  return /*#__PURE__*/React.createElement(\"div\", {\n    className: \"canvas-wrapper\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 149,\n      columnNumber: 5\n    }\n  }, /*#__PURE__*/React.createElement(\"video\", {\n    id: `video-${userId}`,\n    autoPlay: true,\n    muted: true // ref={videoRef}\n    ,\n    playsInline: true,\n    style: {\n      WebkitTransform: \"scaleX(-1)\",\n      transform: \"scaleX(-1)\",\n      visibility: \"hidden\",\n      width: \"auto\",\n      height: \"auto\"\n    },\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 150,\n      columnNumber: 7\n    }\n  }), /*#__PURE__*/React.createElement(\"canvas\", {\n    id: `output-${userId}`,\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 164,\n      columnNumber: 7\n    }\n  }));\n};\n\nexport default FaceTracker;","map":{"version":3,"sources":["/Users/craigpickard/Dev/web/hbo-client/src/components/FaceTracker.js"],"names":["React","useEffect","useState","facemesh","_isNil","TRIANGULATION","triangulateMesh","drawPath","ctx","points","closePath","region","Path2D","moveTo","i","length","point","lineTo","stroke","FaceTracker","videoRef","userId","stream","count","setCount","trackingEnabled","setTrackingEnabled","videoLoaded","setVideoLoaded","uuid","setUuid","faces","model","videoWidth","videoHeight","video","canvas","_init","load","document","getElementById","srcObject","addEventListener","event","console","log","width","height","canvasContainer","querySelector","style","getContext","translate","scale","fillStyle","strokeStyle","lineWidth","renderPrediction","drawImage","Math","floor","parseInt","predictions","estimateFaces","forEach","prediction","keypoints","scaledMesh","map","index","x","y","beginPath","arc","PI","fill","requestAnimationFrame","WebkitTransform","transform","visibility"],"mappings":";AAAA,OAAOA,KAAP,IAAgBC,SAAhB,EAA2BC,QAA3B,QAA2C,OAA3C;AACA,OAAO,KAAKC,QAAZ,MAA0B,6BAA1B;AACA,OAAOC,MAAP,MAAmB,cAAnB;AAEA,SAASC,aAAT,QAA8B,iBAA9B,C,CAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAEA,MAAMC,eAAe,GAAG,IAAxB;;AAEA,SAASC,QAAT,CAAkBC,GAAlB,EAAuBC,MAAvB,EAA+BC,SAA/B,EAA0C;AACxC,QAAMC,MAAM,GAAG,IAAIC,MAAJ,EAAf;AACAD,EAAAA,MAAM,CAACE,MAAP,CAAcJ,MAAM,CAAC,CAAD,CAAN,CAAU,CAAV,CAAd,EAA4BA,MAAM,CAAC,CAAD,CAAN,CAAU,CAAV,CAA5B;;AACA,OAAK,IAAIK,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGL,MAAM,CAACM,MAA3B,EAAmCD,CAAC,EAApC,EAAwC;AACtC,UAAME,KAAK,GAAGP,MAAM,CAACK,CAAD,CAApB;AACAH,IAAAA,MAAM,CAACM,MAAP,CAAcD,KAAK,CAAC,CAAD,CAAnB,EAAwBA,KAAK,CAAC,CAAD,CAA7B;AACD;;AAED,MAAIN,SAAJ,EAAe;AACbC,IAAAA,MAAM,CAACD,SAAP;AACD;;AACDF,EAAAA,GAAG,CAACU,MAAJ,CAAWP,MAAX;AACD;;AAED,MAAMQ,WAAW,GAAG,CAAC;AAAEC,EAAAA,QAAF;AAAYC,EAAAA,MAAZ;AAAoBC,EAAAA;AAApB,CAAD,KAAkC;AACpD,QAAM,CAACC,KAAD,EAAQC,QAAR,IAAoBxB,KAAK,CAACE,QAAN,CAAe,CAAf,CAA1B;AACA,QAAM,CAACuB,eAAD,EAAkBC,kBAAlB,IAAwCxB,QAAQ,CAAC,KAAD,CAAtD;AACA,QAAM,CAACyB,WAAD,EAAcC,cAAd,IAAgC1B,QAAQ,CAAC,KAAD,CAA9C;AACA,QAAM,CAAC2B,IAAD,EAAOC,OAAP,IAAkB5B,QAAQ,CAAC,IAAD,CAAhC;AAEA,MAAI6B,KAAK,GAAG,EAAZ;AACA,MAAIC,KAAK,GAAG,IAAZ;AACA,MAAIxB,GAAJ,EAASyB,UAAT,EAAqBC,WAArB,EAAkCC,KAAlC,EAAyCC,MAAzC;AAEAnC,EAAAA,SAAS,CAAC,MAAM;AACdoC,IAAAA,KAAK;AACN,GAFQ,EAEN,CAACf,MAAD,CAFM,CAAT;;AAIA,iBAAee,KAAf,GAAuB;AACrBL,IAAAA,KAAK,GAAG,MAAM7B,QAAQ,CAACmC,IAAT,EAAd,CADqB,CAGrB;AACA;AACA;;AACAH,IAAAA,KAAK,GAAGI,QAAQ,CAACC,cAAT,CAAyB,SAAQnB,MAAO,EAAxC,CAAR;AACAc,IAAAA,KAAK,CAACM,SAAN,GAAkBnB,MAAlB;AACAa,IAAAA,KAAK,CAACO,gBAAN,CAAuB,YAAvB,EAAqC,MAAOC,KAAP,IAAiB;AACpDC,MAAAA,OAAO,CAACC,GAAR,CACE,4CACE,kDAFJ;AAIAZ,MAAAA,UAAU,GAAGE,KAAK,CAACF,UAAnB;AACAC,MAAAA,WAAW,GAAGC,KAAK,CAACD,WAApB;AACAC,MAAAA,KAAK,CAACW,KAAN,GAAcb,UAAd;AACAE,MAAAA,KAAK,CAACY,MAAN,GAAeb,WAAf;AAEAE,MAAAA,MAAM,GAAGG,QAAQ,CAACC,cAAT,CAAyB,UAASnB,MAAO,EAAzC,CAAT;AACAe,MAAAA,MAAM,CAACU,KAAP,GAAeb,UAAf;AACAG,MAAAA,MAAM,CAACW,MAAP,GAAgBb,WAAhB;AACA,YAAMc,eAAe,GAAGT,QAAQ,CAACU,aAAT,CAAuB,iBAAvB,CAAxB;AACAD,MAAAA,eAAe,CAACE,KAAhB,GAAyB,UAASjB,UAAW,eAAcC,WAAY,IAAvE;AAEA1B,MAAAA,GAAG,GAAG4B,MAAM,CAACe,UAAP,CAAkB,IAAlB,CAAN;AACA3C,MAAAA,GAAG,CAAC4C,SAAJ,CAAchB,MAAM,CAACU,KAArB,EAA4B,CAA5B;AACAtC,MAAAA,GAAG,CAAC6C,KAAJ,CAAU,CAAC,CAAX,EAAc,CAAd;AACA7C,MAAAA,GAAG,CAAC8C,SAAJ,GAAgB,SAAhB;AACA9C,MAAAA,GAAG,CAAC+C,WAAJ,GAAkB,SAAlB;AACA/C,MAAAA,GAAG,CAACgD,SAAJ,GAAgB,GAAhB;AACA5B,MAAAA,cAAc,CAAC,IAAD,CAAd;AACA6B,MAAAA,gBAAgB;AACjB,KAxBD;AAyBD;;AAED,iBAAeA,gBAAf,GAAkC;AAChCjD,IAAAA,GAAG,CAACkD,SAAJ,CACEvB,KADF,EAEE,CAFF,EAGE,CAHF,EAIEF,UAJF,EAKEC,WALF,EAMEyB,IAAI,CAACC,KAAL,CAAWC,QAAQ,CAACxC,MAAD,CAAR,GAAmBe,MAAM,CAACU,KAArC,CANF,EAOEa,IAAI,CAACC,KAAL,CAAWC,QAAQ,CAACxC,MAAD,CAAR,GAAmBe,MAAM,CAACW,MAArC,CAPF,EAQEX,MAAM,CAACU,KART,EASEV,MAAM,CAACW,MATT;;AAYA,QAAItB,eAAJ,EAAqB;AACnB,YAAMqC,WAAW,GAAG,MAAM9B,KAAK,CAAC+B,aAAN,CAAoB5B,KAApB,CAA1B;;AACA,UAAI2B,WAAW,CAAC/C,MAAZ,GAAqB,CAAzB,EAA4B;AAC1B+C,QAAAA,WAAW,CAACE,OAAZ,CAAqBC,UAAD,IAAgB;AAClC,gBAAMC,SAAS,GAAGD,UAAU,CAACE,UAA7B;;AACA,cAAI7D,eAAJ,EAAqB;AACnB,iBAAK,IAAIQ,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGT,aAAa,CAACU,MAAd,GAAuB,CAA3C,EAA8CD,CAAC,EAA/C,EAAmD;AACjD,oBAAML,MAAM,GAAG,CACbJ,aAAa,CAACS,CAAC,GAAG,CAAL,CADA,EAEbT,aAAa,CAACS,CAAC,GAAG,CAAJ,GAAQ,CAAT,CAFA,EAGbT,aAAa,CAACS,CAAC,GAAG,CAAJ,GAAQ,CAAT,CAHA,EAIbsD,GAJa,CAIRC,KAAD,IAAWH,SAAS,CAACG,KAAD,CAJX,CAAf;AAMA9D,cAAAA,QAAQ,CAACC,GAAD,EAAMC,MAAN,EAAc,IAAd,CAAR;AACD;AACF,WAVD,MAUO;AACL,iBAAK,IAAIK,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGoD,SAAS,CAACnD,MAA9B,EAAsCD,CAAC,EAAvC,EAA2C;AACzC,oBAAMwD,CAAC,GAAGJ,SAAS,CAACpD,CAAD,CAAT,CAAa,CAAb,CAAV;AACA,oBAAMyD,CAAC,GAAGL,SAAS,CAACpD,CAAD,CAAT,CAAa,CAAb,CAAV;AAEAN,cAAAA,GAAG,CAACgE,SAAJ;AACAhE,cAAAA,GAAG,CAACiE,GAAJ,CAAQH,CAAR,EAAWC,CAAX,EAAc;AAAE;AAAhB,gBAA8B,CAA9B,EAAiC,IAAIZ,IAAI,CAACe,EAA1C;AACAlE,cAAAA,GAAG,CAACmE,IAAJ;AACD;AACF;AACF,SAtBD;AAuBD;AACF,KAxC+B,CAyChC;;;AAEAC,IAAAA,qBAAqB,CAACnB,gBAAD,CAArB;AACD,GA7FmD,CA+FpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAEA,sBACE;AAAK,IAAA,SAAS,EAAC,gBAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACE;AACE,IAAA,EAAE,EAAG,SAAQpC,MAAO,EADtB;AAEE,IAAA,QAAQ,MAFV;AAGE,IAAA,KAAK,MAHP,CAIE;AAJF;AAKE,IAAA,WAAW,MALb;AAME,IAAA,KAAK,EAAE;AACLwD,MAAAA,eAAe,EAAE,YADZ;AAELC,MAAAA,SAAS,EAAE,YAFN;AAGLC,MAAAA,UAAU,EAAE,QAHP;AAILjC,MAAAA,KAAK,EAAE,MAJF;AAKLC,MAAAA,MAAM,EAAE;AALH,KANT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IADF,eAeE;AAAQ,IAAA,EAAE,EAAG,UAAS1B,MAAO,EAA7B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAfF,CADF;AAmBD,CA3HD;;AA6HA,eAAeF,WAAf","sourcesContent":["import React, { useEffect, useState } from \"react\";\nimport * as facemesh from \"@tensorflow-models/facemesh\";\nimport _isNil from \"lodash/isNil\";\n\nimport { TRIANGULATION } from \"./triangulation\";\n\n// const useAnimationFrame = (callback) => {\n//   // Use useRef for mutable variables that we want to persist\n//   // without triggering a re-render on their change\n//   const requestRef = React.useRef();\n//   const previousTimeRef = React.useRef();\n\n//   const animate = (time) => {\n//     if (previousTimeRef.current != undefined) {\n//       const deltaTime = time - previousTimeRef.current;\n//       callback(deltaTime);\n//     }\n//     previousTimeRef.current = time;\n//     requestRef.current = requestAnimationFrame(animate);\n//   };\n\n//   React.useEffect(() => {\n//     requestRef.current = requestAnimationFrame(animate);\n//     return () => cancelAnimationFrame(requestRef.current);\n//   }, []); // Make sure the effect runs only once\n// };\n\nconst triangulateMesh = true;\n\nfunction drawPath(ctx, points, closePath) {\n  const region = new Path2D();\n  region.moveTo(points[0][0], points[0][1]);\n  for (let i = 1; i < points.length; i++) {\n    const point = points[i];\n    region.lineTo(point[0], point[1]);\n  }\n\n  if (closePath) {\n    region.closePath();\n  }\n  ctx.stroke(region);\n}\n\nconst FaceTracker = ({ videoRef, userId, stream }) => {\n  const [count, setCount] = React.useState(0);\n  const [trackingEnabled, setTrackingEnabled] = useState(false);\n  const [videoLoaded, setVideoLoaded] = useState(false);\n  const [uuid, setUuid] = useState(null);\n\n  let faces = [];\n  let model = null;\n  let ctx, videoWidth, videoHeight, video, canvas;\n\n  useEffect(() => {\n    _init();\n  }, [stream]);\n\n  async function _init() {\n    model = await facemesh.load();\n\n    // Pass in a video stream to the model to obtain\n    // an array of detected faces from the MediaPipe graph.\n    // video = document.querySelector(\"video\");\n    video = document.getElementById(`video-${userId}`);\n    video.srcObject = stream;\n    video.addEventListener(\"loadeddata\", async (event) => {\n      console.log(\n        \"Yay! The readyState just increased to  \" +\n          \"HAVE_CURRENT_DATA or greater for the first time.\"\n      );\n      videoWidth = video.videoWidth;\n      videoHeight = video.videoHeight;\n      video.width = videoWidth;\n      video.height = videoHeight;\n\n      canvas = document.getElementById(`output-${userId}`);\n      canvas.width = videoWidth;\n      canvas.height = videoHeight;\n      const canvasContainer = document.querySelector(\".canvas-wrapper\");\n      canvasContainer.style = `width: ${videoWidth}px; height: ${videoHeight}px`;\n\n      ctx = canvas.getContext(\"2d\");\n      ctx.translate(canvas.width, 0);\n      ctx.scale(-1, 1);\n      ctx.fillStyle = \"#32EEDB\";\n      ctx.strokeStyle = \"#32EEDB\";\n      ctx.lineWidth = 0.5;\n      setVideoLoaded(true);\n      renderPrediction();\n    });\n  }\n\n  async function renderPrediction() {\n    ctx.drawImage(\n      video,\n      0,\n      0,\n      videoWidth,\n      videoHeight,\n      Math.floor(parseInt(userId) * canvas.width),\n      Math.floor(parseInt(userId) * canvas.height),\n      canvas.width,\n      canvas.height\n    );\n\n    if (trackingEnabled) {\n      const predictions = await model.estimateFaces(video);\n      if (predictions.length > 0) {\n        predictions.forEach((prediction) => {\n          const keypoints = prediction.scaledMesh;\n          if (triangulateMesh) {\n            for (let i = 0; i < TRIANGULATION.length / 3; i++) {\n              const points = [\n                TRIANGULATION[i * 3],\n                TRIANGULATION[i * 3 + 1],\n                TRIANGULATION[i * 3 + 2],\n              ].map((index) => keypoints[index]);\n\n              drawPath(ctx, points, true);\n            }\n          } else {\n            for (let i = 0; i < keypoints.length; i++) {\n              const x = keypoints[i][0];\n              const y = keypoints[i][1];\n\n              ctx.beginPath();\n              ctx.arc(x, y, 1 /* radius */, 0, 2 * Math.PI);\n              ctx.fill();\n            }\n          }\n        });\n      }\n    }\n    // ctx.clearRect(0, 0, canvas.width, canvas.height);\n\n    requestAnimationFrame(renderPrediction);\n  }\n\n  //   useAnimationFrame(async (deltaTime) => {\n  //     // Pass on a function to the setter of the state\n  //     // to make sure we always have the latest state\n  //     console.log(\"animate\");\n  //     if (model !== null) faces = await model.estimateFaces(video);\n  //     // faces.forEach((face) => console.log(face.scaledMesh));\n  //     console.log(faces.length);\n  //   });\n\n  return (\n    <div className=\"canvas-wrapper\">\n      <video\n        id={`video-${userId}`}\n        autoPlay\n        muted\n        // ref={videoRef}\n        playsInline\n        style={{\n          WebkitTransform: \"scaleX(-1)\",\n          transform: \"scaleX(-1)\",\n          visibility: \"hidden\",\n          width: \"auto\",\n          height: \"auto\",\n        }}\n      />\n      <canvas id={`output-${userId}`}></canvas>\n    </div>\n  );\n};\n\nexport default FaceTracker;\n"]},"metadata":{},"sourceType":"module"}